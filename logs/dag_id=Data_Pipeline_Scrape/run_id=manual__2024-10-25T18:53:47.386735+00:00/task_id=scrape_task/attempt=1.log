[2024-10-25T18:53:48.738+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: Data_Pipeline_Scrape.scrape_task manual__2024-10-25T18:53:47.386735+00:00 [queued]>
[2024-10-25T18:53:48.744+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: Data_Pipeline_Scrape.scrape_task manual__2024-10-25T18:53:47.386735+00:00 [queued]>
[2024-10-25T18:53:48.744+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-10-25T18:53:48.744+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2024-10-25T18:53:48.744+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-10-25T18:53:48.750+0000] {taskinstance.py:1300} INFO - Executing <Task(PythonOperator): scrape_task> on 2024-10-25 18:53:47.386735+00:00
[2024-10-25T18:53:48.763+0000] {standard_task_runner.py:55} INFO - Started process 114 to run task
[2024-10-25T18:53:48.765+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Data_Pipeline_Scrape', 'scrape_task', 'manual__2024-10-25T18:53:47.386735+00:00', '--job-id', '48', '--raw', '--subdir', 'DAGS_FOLDER/test-***.py', '--cfg-path', '/tmp/tmpytcicagv']
[2024-10-25T18:53:48.767+0000] {standard_task_runner.py:83} INFO - Job 48: Subtask scrape_task
[2024-10-25T18:53:48.801+0000] {task_command.py:388} INFO - Running <TaskInstance: Data_Pipeline_Scrape.scrape_task manual__2024-10-25T18:53:47.386735+00:00 [running]> on host 5aa9033948a7
[2024-10-25T18:53:48.845+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=santosh
AIRFLOW_CTX_DAG_ID=Data_Pipeline_Scrape
AIRFLOW_CTX_TASK_ID=scrape_task
AIRFLOW_CTX_EXECUTION_DATE=2024-10-25T18:53:47.386735+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-10-25T18:53:47.386735+00:00
[2024-10-25T18:53:48.846+0000] {logging_mixin.py:137} INFO - Running scrape task function...
[2024-10-25T18:53:48.846+0000] {logging_mixin.py:137} INFO - Output directory created or exists: /opt/***/data/raw
[2024-10-25T18:53:48.846+0000] {logging_mixin.py:137} INFO - Starting the scraping process...
[2024-10-25T18:53:48.846+0000] {logging_mixin.py:137} INFO - Current week for scraping: 1
[2024-10-25T18:53:48.846+0000] {logging_mixin.py:137} INFO - Sections to scrape: {'section-1': ['https://rc-docs.northeastern.edu/en/latest/connectingtocluster/index.html#']}
[2024-10-25T18:53:48.846+0000] {logging_mixin.py:137} INFO - running get_all_links
[2024-10-25T18:53:49.089+0000] {logging_mixin.py:137} INFO - running get_all_links
[2024-10-25T18:53:49.187+0000] {logging_mixin.py:137} INFO - running get_all_links
[2024-10-25T18:53:49.311+0000] {logging_mixin.py:137} INFO - running get_all_links
[2024-10-25T18:53:49.415+0000] {logging_mixin.py:137} INFO - running get_all_links
[2024-10-25T18:53:49.543+0000] {logging_mixin.py:137} INFO - section-1 has 60 links
[2024-10-25T18:53:49.544+0000] {logging_mixin.py:137} INFO - Fetched links: {'section-1': ['https://rc-docs.northeastern.edu/en/latest/datamanagement/index.html', 'https://rc-docs.northeastern.edu/en/latest/software/index.html', 'https://rc-docs.northeastern.edu/en/latest/best-practices/scratchpurge.html', 'https://rc-docs.northeastern.edu/en/latest/gpus/index.html', 'https://rc-docs.northeastern.edu/en/latest/best-practices/index.html', 'https://rc-docs.northeastern.edu/en/latest/software/packagemanagers/conda.html', 'https://rc-docs.northeastern.edu/en/latest/glossary.html', 'https://rc-docs.northeastern.edu/en/latest/connectingtocluster/index.html#using-the-terminal', 'https://rc-docs.northeastern.edu/en/latest/runningjobs/index.html', 'https://rc-docs.northeastern.edu/en/latest/runningjobs/runningsjob.html', 'https://rc-docs.northeastern.edu/en/latest/slurmguide/index.html', 'https://rc-docs.northeastern.edu/en/latest/classroom/index.html', 'https://rc-docs.northeastern.edu/en/latest/software/systemwide/matlab.html', 'https://rc.northeastern.edu', 'https://rc-docs.northeastern.edu/en/latest/containers/singularity.html', 'https://rc-docs.northeastern.edu/en/latest/software/packagemanagers/index.html', 'https://rc-docs.northeastern.edu/en/latest/software/fromsource/index.html', 'https://rc-docs.northeastern.edu/en/latest/connectingtocluster/index.html#using-open-ondemand', 'https://rc-docs.northeastern.edu/en/latest/best-practices/clusterusage.html', 'https://rc-docs.northeastern.edu/en/latest/classroom/cps_ood.html', 'https://rc-docs.northeastern.edu/en/latest/faqs-new.html', 'https://rc-docs.northeastern.edu/en/latest/slurmguide/slurmmonitoringandmanaging.html', 'https://rc-docs.northeastern.edu/en/latest/datamanagement/discovery_storage.html', 'https://github.com/pradyunsg/furo', 'https://rc-docs.northeastern.edu/en/latest/gpus/gpuoverview.html', 'https://rc-docs.northeastern.edu/en/latest/software/systemwide/modules.html', 'https://rc-docs.northeastern.edu/en/latest/datamanagement/globus.html', 'https://rc-docs.northeastern.edu/en/latest/connectingtocluster/linux.html', 'https://rc-docs.northeastern.edu/en/latest/gpus/gpujobsubmission.html', 'https://rc-docs.northeastern.edu/en/latest/gpus/accessinggpus.html', 'https://github.com/northeastern-rc/rc-public-documentation', 'https://rc-docs.northeastern.edu/en/latest/runningjobs/understandingqueuing.html', 'https://rc-docs.northeastern.edu/en/latest/slurmguide/slurmcommands.html', 'https://rc-docs.northeastern.edu/en/latest/classroom/cheatsheet.html', 'https://rc-docs.northeastern.edu/en/latest/gpus/multigpu-partition-access.html', 'https://rc-docs.northeastern.edu/en/latest/software/systemwide/index.html', 'https://rc-docs.northeastern.edu/en/latest/software/packagemanagers/spack.html', 'https://rc-docs.northeastern.edu/en/latest/software/fromsource/makefile.html', 'https://rc-docs.northeastern.edu/en/latest/connectingtocluster/windows.html', 'https://rc-docs.northeastern.edu/en/latest/connectingtocluster/mac.html', 'https://rc-docs.northeastern.edu/en/latest/slurmguide/slurmarray.html', 'https://rc-docs.northeastern.edu/en/latest/classroom/class_guide.html', 'https://rc-docs.northeastern.edu/en/latest/connectingtocluster/index.html', 'https://rc-docs.northeastern.edu/en/latest/datamanagement/transferringdata.html', 'https://rc-docs.northeastern.edu/en/latest/_sources/connectingtocluster/index.md.txt', 'https://rc-docs.northeastern.edu/en/latest/connectingtocluster/index.html#connecting-to-cluster', 'https://rc-docs.northeastern.edu/en/latest/software/systemwide/r.html', 'https://www.ssh.com/ssh/protocol/', 'https://rc.northeastern.edu/ood/', 'https://rc-docs.northeastern.edu/en/latest/index.html', 'https://rc-docs.northeastern.edu/en/latest/connectingtocluster/index.html#furo-main-content', 'https://rc-docs.northeastern.edu/en/latest/runningjobs/jobscheduling.html', 'https://rc-docs.northeastern.edu/en/latest/best-practices/homequota.html', 'https://rc-docs.northeastern.edu/en/latest/software/fromsource/cmake.html', 'https://rc-docs.northeastern.edu/en/latest/best-practices/shell_environment.html', 'https://rc-docs.northeastern.edu/en/latest/best-practices/checkpointing.html', 'https://rc-docs.northeastern.edu/en/latest/containers/index.html', 'https://rc-docs.northeastern.edu/en/latest/best-practices/workquota.html', 'https://rc-docs.northeastern.edu/en/latest/runningjobs/interactiveandbatch.html', 'https://rc-docs.northeastern.edu/en/latest/software/systemwide/mpi.html']}
[2024-10-25T18:53:49.544+0000] {logging_mixin.py:137} INFO - Arranging scraped data...
[2024-10-25T18:53:49.548+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/test-airflow.py", line 48, in scrape_task_func
    scraped_sections = scrape_sections_up_to_current_week()
  File "/opt/airflow/src/data_pipeline/scraper.py", line 54, in scrape_sections_up_to_current_week
    arrange_scraped_data(fetched_links)
  File "/opt/airflow/src/data_pipeline/arrange.py", line 31, in arrange_scraped_data
    os.makedirs(dir_path, exist_ok=True)
  File "/usr/local/lib/python3.7/os.py", line 213, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/local/lib/python3.7/os.py", line 213, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/usr/local/lib/python3.7/os.py", line 223, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '../../data'
[2024-10-25T18:53:49.556+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=Data_Pipeline_Scrape, task_id=scrape_task, execution_date=20241025T185347, start_date=20241025T185348, end_date=20241025T185349
[2024-10-25T18:53:49.563+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 48 for task scrape_task ([Errno 13] Permission denied: '../../data'; 114)
[2024-10-25T18:53:49.588+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2024-10-25T18:53:49.604+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
